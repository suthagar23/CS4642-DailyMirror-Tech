{"fileName": "managing-the-dark-side-of-social-32116.html", "title": "Managing the Dark Side of Social", "date_posted": "2013-07-09 07:29:03", "total_views": "17539", "total_comments": "0", "image_urls": [], "content": "Facebook faced a massive wave of protest over the past days over postings on its social network that many claimed (rightly) degraded women, including content on groups such as \u201cthis is why Indian girls get raped.\u201d In response, over 40 women\u2019s groups and individuals started the FBrape campaign, which called for Facebook to remove content that portrays violence to women positively. The initiative has generated thousands of tweets and online petition signatures, including emails targeting to brands that were unknowingly running advertising on some of these pages.\nFacebook has an existing policy in place that enables users to report any content that may be perceived as vulgar and distasteful. In fact, Facebook has regularly removed content from the network, most notably things perceived as being hateful to various ethnic groups. However, with the network now reaching over a billion people, Facebook will need to reassure both users and advertisers that they can accurately and swiftly review and manage the massive amount of content produced by the social graph \u2013 last reported to be around 2.5 billion pieces of content and 500+ terabytes of data each day.\u00a0 Furthermore, they will need to find a logical and objective way to evaluate what content is ultimately offensive. While nobody would argue around the disgraceful pages highlighted by FBrape, other content may prove to be more contentious and opaque.\nThe Internet has always had a chaotic, \u201cwild west\u201d element to it since the early days. Indeed, there are still many dark corners and ill-intentioned people online, and some periodically find their way into mainstream destinations like Facebook. Publishers and agencies have worked over the years to develop and/or embrace technology that provides advertisers with a much higher degree of brand security so their ads will not appear on pages with inappropriate content, everything ranging from sexually explicit images to news event (e.g., an airline ad next to airplane crash news report).\u00a0 Specialist suppliers like Evidon and DoubleVerify are expanding and getting vastly better at protecting brands at scale, i.e., across massive amounts of media inventory in real-time. In simple terms, every media page is scanned for offensive content, which can be defined and dialed-up or down by the advertiser, and a decision is then made in real-time by rules whether the page is acceptable for the brand\u2019s advertising. While great comfort to advertisers, a few words of caution need to be shared. First, no technology works 100% of the time, and the dark side of the Internet continues to use technology and other means to bypass security systems. So it\u2019s a continuous and never ending battle, and an unfortunate but persistent risk of online advertising.\u00a0 Second, on Facebook, these technologies are constrained due to the network\u2019s \u201cclosed\u201d system as well as their targeting model around demographics, categories, and interests in a content ecosystem that is largely consumer-generated not professionally published.\nThe FBrape campaign has brought the issue to the public forefront, and may be the catalyst needed for Facebook to both improve brand security to advertisers and further eliminate offensive content. Facebook has already responded with an admission that their systems need to be updated. In the meantime, Mindshare and GroupM will continue to collaborate with the Facebook Client Council, which is due to meet imminently, as well as the industry\u2019s leading technologies to strengthen brand protection.\u00a0 However, in the end, it will be up to Facebook to deliver or at least facilitate this protection layer in their ecosystem. If they don\u2019t they may end up losing the \u201clikes\u201d of both advertisers and people.\n", "comments": []}